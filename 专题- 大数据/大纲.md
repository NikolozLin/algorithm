# 大数据题目解题技巧

1. 哈希函数可以把数据按种类均匀分流
2. 布隆过滤器 用于集合的建立与查询， 并节省大量空间
3. 一致性哈希解决 数据服务器负载管理问题
4. 使用并查集结构做岛问题的并行计算
5. 位图 解决某一范围上数字出现的情况，并节省大量空间
6. 利用分段统计思想、并进一步节省大量空间
7. 利用堆、外排序来做多个单元的结果合并

## 问题一

原问题：
> 32位无符号整数的范围是0-4294967295，现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然有没出现过的数。最多一可使用1GB的内存空间，怎么找到左右没出现过的数？
进阶：
> 内存限制为10MB，但是只用找到一个没有出现过的数即可。
解：

- 内存限制1G
  1.创建一个2^32个`bit`的数组，大概需要 （2^32/8/1024/1024）512MB的内存空间
  2.从文件中取数x 并在`bitArray[x]`设定为1
  3.然后在 遍历bitArray 那个index值为0 那就没出现

- 限制内存为3Kb
  1. js中 number是双精度64位浮点，占8字节 Byte
  2. 3KB/8Byte =375 ，去2的倍数最接近的375的值，256
  3. 数据范围0～2^32-1 分为256个区间。  `array.lenght=256`
  4. 一份的区间范围 R=2^32/256
  5. 在文件中取数X， X/R=Y ， 那么`array[Y]+=1`
  6. 在256份中，最少的一份 表示数据缺失数据。

  7. 数据缺失的一份数据为A，重复3～7过程。
  8. 得到缺失的数据

## 问题二

原问题：
> 一个包含100亿的URL的大文件, 每个URL占用64B,请找出其中所有重复的URL
解： 布隆过滤器（需要允许有误差）
> 某公司一天用户搜索词汇的百亿数据量, 请设计出一种求出每天热门词汇 Top100的可行办法
解： （堆）

1. 所有的词Hash，统计词频并且分块。然后个块建立大根堆
2. 取出所有的块的堆顶，组成一个新大根堆A
3. 弹出A堆顶x，x为Top热门词，
4. 同时在x原来所堆弹出堆顶元素，补充到A当中。

## 问题三

原问题：
> 32位无符号整数的范围是0-4294967295，现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然有没出现过的数。最多一可使用1GB的内存空间， 找出所有出现了两次的数！！！
进阶：
> 内存限制为10MB或10KB，但是只用找到40亿的中位数

解：

- 找出出现两次的数：
  - 使用哈希分流
    1. 先按范围分成多个小文件。
    2. 处理每个小文件，处理每个整数值并记录出现频率
  - 使用 bitMap
    > 需要记录词频，需要用两个bit进行记录  00没出现  ，01出现一次 10出现两次 11:出现两次及以上

    1.创建一个`2^32 *2`个`bit`的数组，大概需要 （2^32*2/8/1024/1024）1GB的内存空间
    2.从文件中取数x 并在`bitArray`的 2x 的位置 设置状态。
    3.如果 遍历过程中 如果出现10 或11 那就出现了两次。

- 找出40亿的中位数：
    > 使用范围统计的思想，
    1. js中 number是双精度64位浮点，占8字节 Byte
    2. 10KB/8Byte =1250 ，去2的倍数最接近的1250的值，1024
    3. 数据范围0～2^32-1 分为1024个区间。  `array.lenght=1024`
    4. 一份的区间范围 R=2^32/1024 =
    5. 在文件中取数X， X/R=Y ， 那么`array[Y]+=1`
    6. 一共40亿个无符号整数，在1024份，逐份累加，当累计到20亿，那么中位数在最后的分组范围A。
    7. 最后分组累计超过20亿了， 假设前面的分组累计到18亿，那么中位数在最后分组A两亿个的位置。

    8.循环上面过程最后找到中位数

## 问题四

> 10GB的文件，每个文件都是一个有符号整数，但是文件无序。 现在内存5G ，要求吧文件变得有序。

解：
> 利用外排序，
>
  1. 按可用内存大小，计算内存放置多少个元素。
  2. 内存存放元素个数`X`= 内存容量/（元素本身的字节大小+元素出现个数(jsNumber占8字节)）
  3. 所有的整数范围分开成`R`份  `R=整数范围/X`
  4. 内存建立一个 `小根堆`，遍整个大文件，将第一个范围的的数，放入内存小根堆中
  5. 输出内存堆到新文件中
  6. 循环4-5，处理每个范围的数并输出到新文件中。
